{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tok.ipynb","provenance":[],"authorship_tag":"ABX9TyNTgVxt8TdpwR5OUixzCgwW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"v7_aUP_CGXFv"},"outputs":[],"source":["import pickle\n","f = open('tokenizer.pickle', 'rb')\n","tokenizer = pickle.load(f)\n","\n","def tokenize(sentences):\n","  sequences = tokenizer.texts_to_sequences(sentences)\n","  padded = pad_sequences(sequences, maxlen=120, padding='post', truncating='post')\n","  return padded"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"Vj49Mr631bKv"}},{"cell_type":"code","source":["import googleapiclient.discovery\n","\n","def predict_json(project, region, model, instances, version=None):\n","    \"\"\"Send json data to a deployed model for prediction.\n","\n","    Args:\n","        project (str): project where the Cloud ML Engine Model is deployed.\n","        region (str): regional endpoint to use; set to None for ml.googleapis.com\n","        model (str): model name.\n","        instances ([Mapping[str: Any]]): Keys should be the names of Tensors\n","            your deployed model expects as inputs. Values should be datatypes\n","            convertible to Tensors, or (potentially nested) lists of datatypes\n","            convertible to tensors.\n","        version: str, version of the model to target.\n","    Returns:\n","        Mapping[str: any]: dictionary of prediction results defined by the\n","            model.\n","    \"\"\"\n","    # Create the ML Engine service object.\n","    # To authenticate set the environment variable\n","    # GOOGLE_APPLICATION_CREDENTIALS=<path_to_service_account_file>\n","    prefix = \"{}-ml\".format(region) if region else \"ml\"\n","    api_endpoint = \"https://{}.googleapis.com\".format(prefix)\n","    client_options = ClientOptions(api_endpoint=api_endpoint)\n","    service = googleapiclient.discovery.build(\n","        'ml', 'v1', client_options=client_options)\n","    name = 'projects/{}/models/{}'.format(project, model)\n","\n","    if version is not None:\n","        name += '/versions/{}'.format(version)\n","\n","    response = service.projects().predict(\n","        name=name,\n","        body={'instances': instances}\n","    ).execute()\n","\n","    if 'error' in response:\n","        raise RuntimeError(response['error'])\n","\n","    return response['predictions']"],"metadata":{"id":"38S6Dm8a1a1r"},"execution_count":null,"outputs":[]}]}